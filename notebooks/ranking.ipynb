{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa35c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.cv_iterator import leave_last_k\n",
    "from src.features.features import feature_engineering\n",
    "from src.features.utils import build_rank_input\n",
    "from src.models.tuner import BayesianSearch\n",
    "from src.models.ranker import Ranker\n",
    "from src.models.evaluator import Evaluation, recs_score\n",
    "from src.models.tracker import launch_mlflow, log_run\n",
    "from src.models.utils import set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file\n",
    "\n",
    "# ensure reproducibility\n",
    "set_global_seed(seed=config[\"general\"][\"seed\"])\n",
    "\n",
    "# set experiment tracking\n",
    "launch_mlflow()\n",
    "\n",
    "# set algorithm\n",
    "ALGORITHM = \"XGBRanker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569496d",
   "metadata": {},
   "source": [
    "**Data Preparation & Train/Test Split**\n",
    "\n",
    "- Load and transform the 3 datasets\n",
    "- Split whole set into train, validation and test sets by segmenting it temporally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb620d",
   "metadata": {},
   "source": [
    "**Training Set Enrichment**\n",
    "\n",
    "- (negative sampling, to be added)\n",
    "- Feature Engineering: creates cross user-item features for ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85b542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build features for ranking model\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "df_train, df_valid = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features)\n",
    "    for df in (df_train, df_valid)\n",
    "    ]\n",
    "\n",
    "del user_item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a761c",
   "metadata": {},
   "source": [
    "**Optimization & Evaluation**\n",
    "\n",
    "- Hyper-parameters - search which hyper-parameters optimize scoring metric for the given algorithm in the validation set\n",
    "- Evaluation - retrieve best hyper-parameters and recover full training set to evaluate results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2fdc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 23:53:55,893] A new study created in memory with name: no-name-f70258c3-0904-44bf-afa7-5f922045666e\n",
      "[I 2025-07-01 23:54:02,140] Trial 0 finished with value: 0.9475287274655356 and parameters: {'learning_rate': 0.1878955193048339, 'gamma': 9.50714306409916, 'max_depth': 12, 'subsample': 0.7993292420985183, 'n_estimators': 104}. Best is trial 0 with value: 0.9475287274655356.\n",
      "[I 2025-07-01 23:54:18,614] Trial 1 finished with value: 0.9460424920466596 and parameters: {'learning_rate': 0.07884126564776513, 'gamma': 0.5808361216819946, 'max_depth': 14, 'subsample': 0.8005575058716043, 'n_estimators': 298}. Best is trial 0 with value: 0.9475287274655356.\n",
      "[I 2025-07-01 23:54:23,277] Trial 2 finished with value: 0.9475509544008482 and parameters: {'learning_rate': 0.011271662653605422, 'gamma': 9.699098521619943, 'max_depth': 13, 'subsample': 0.6061695553391381, 'n_estimators': 113}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:54:28,445] Trial 3 finished with value: 0.9459066595970308 and parameters: {'learning_rate': 0.09251885041686347, 'gamma': 3.0424224295953772, 'max_depth': 9, 'subsample': 0.7159725093210578, 'n_estimators': 152}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:54:35,315] Trial 4 finished with value: 0.9434810922587487 and parameters: {'learning_rate': 0.30631459446646736, 'gamma': 1.3949386065204183, 'max_depth': 6, 'subsample': 0.6831809216468459, 'n_estimators': 210}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:54:38,880] Trial 5 finished with value: 0.9467402651113468 and parameters: {'learning_rate': 0.3928028047351138, 'gamma': 1.9967378215835974, 'max_depth': 9, 'subsample': 0.7962072844310213, 'n_estimators': 66}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:54:49,011] Trial 6 finished with value: 0.9464119512195122 and parameters: {'learning_rate': 0.30416488109881773, 'gamma': 1.7052412368729153, 'max_depth': 3, 'subsample': 0.9744427686266666, 'n_estimators': 388}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:54:55,229] Trial 7 finished with value: 0.947136235418876 and parameters: {'learning_rate': 0.4043902767101141, 'gamma': 3.0461376917337066, 'max_depth': 4, 'subsample': 0.8421165132560784, 'n_estimators': 204}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:55:00,408] Trial 8 finished with value: 0.9474080911983034 and parameters: {'learning_rate': 0.06189707918754463, 'gamma': 4.951769101112702, 'max_depth': 3, 'subsample': 0.954660201039391, 'n_estimators': 140}. Best is trial 2 with value: 0.9475509544008482.\n",
      "[I 2025-07-01 23:55:05,396] Trial 9 finished with value: 0.9448797985153764 and parameters: {'learning_rate': 0.331598619892637, 'gamma': 3.1171107608941098, 'max_depth': 9, 'subsample': 0.7733551396716398, 'n_estimators': 114}. Best is trial 2 with value: 0.9475509544008482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run 01JUL2025 at: http://127.0.0.1:5000/#/experiments/859922637182404151/runs/12424e8a637e4194b437e3af7e45f7dc\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/859922637182404151\n",
      "ðŸƒ View run XGBRanker at: http://127.0.0.1:5000/#/experiments/859922637182404151/runs/9ae3d7ebb12e4e87ae922894db06c52e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/859922637182404151\n"
     ]
    }
   ],
   "source": [
    "# set tuner for hyperparam optimization\n",
    "tuner = BayesianSearch(\n",
    "    config[\"optimization\"],\n",
    "    method=\"ranker\",\n",
    "    algorithm=ALGORITHM\n",
    "    )\n",
    "\n",
    "def objective(trial) -> float:\n",
    "    return tuner.fit(df_train, df_valid, trial)\n",
    "\n",
    "# set study\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=config[\"general\"][\"seed\"])\n",
    "    )\n",
    "study.optimize(objective, n_trials= config[\"optimization\"][\"n_trials\"])\n",
    "\n",
    "# logging experiment\n",
    "log_run(experiment_name=\"Ranker\", study=study, tuner=tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9039a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get anti test-set, i.e., train & validation sets together\n",
    "df_train = dfs['data'].merge(\n",
    "    df_test\n",
    "    , on=['user_id', 'item_id', 'rating'], how='left'\n",
    "    , indicator=True\n",
    "    )\n",
    "df_train = df_train[df_train['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "# create features for ranking model\n",
    "user_item_features = feature_engineering(\n",
    "    dataframes={'user': dfs['user'], 'item': dfs['item'], 'data': df_train}\n",
    "    )\n",
    "\n",
    "df_train, df_test = [\n",
    "    build_rank_input(ratings=df.iloc[:,:3], features=user_item_features) for df in (df_train, df_test)\n",
    "    ]\n",
    "\n",
    "del user_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771bf1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.950603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.952903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ndcg\n",
       "dataset          \n",
       "train    0.950603\n",
       "test     0.952903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set algorithm best hyperparams\n",
    "hyperparams = (\n",
    "    config[\"optimization\"][\"ranker\"][ALGORITHM][\"fixed\"]\n",
    "    | study.best_trial.params\n",
    ")\n",
    "\n",
    "# fit model on whole training set\n",
    "clf = Ranker(algorithm=ALGORITHM, params=hyperparams)\n",
    "clf.fit(X=df_train[\"X\"], y=df_train[\"y\"], group=df_train[\"group\"])\n",
    "\n",
    "# test set evaluation\n",
    "scorer = Evaluation(clf=clf)\n",
    "scorer.fit(train=tuple(df_train.values()), test=tuple(df_test.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc255b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shouldn't be done with test set\n",
    "# recs_score(df_test.iloc[:, :2], df_train.iloc[:, :3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
