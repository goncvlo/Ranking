{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d84d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.data.load import load_data\n",
    "from src.data.prepare import prepare_data\n",
    "from src.models.utils import leave_last_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08682abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader= yaml.SafeLoader)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2570c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "dfs = load_data(config=config['data_loader'])\n",
    "dfs = prepare_data(dataframes=dfs, config=config[\"data_preparation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a418bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = leave_last_k(df=dfs['data'], config=config['optimization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of ratings per user and item\n",
    "for col in ['user_id', 'item_id']:\n",
    "    df = df_train.groupby(by=[col]).size().reset_index().rename(columns={0: 'size'})\n",
    "\n",
    "    # compute summary stats\n",
    "    stats = {\n",
    "        'Min': df['size'].min()\n",
    "        , '1st Quartile': df['size'].quantile(0.25)\n",
    "        , 'Median': df['size'].median()\n",
    "        , 'Mean': df['size'].mean()\n",
    "        , '3rd Quartile': df['size'].quantile(0.75)\n",
    "        , 'Max': df['size'].max()\n",
    "    }\n",
    "\n",
    "    # plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df['size'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "    # add vertical lines for stats\n",
    "    for label, value in stats.items():\n",
    "        plt.axvline(x=value, color='red', linestyle='--', label=f'{label}: {value:.2f}')\n",
    "\n",
    "    # plot settings\n",
    "    plt.title(f'Distribution of Ratings Per {col.split(sep=\"_\")[0].capitalize()}')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel(f'Number of {col.split(sep=\"_\")[0].capitalize()}s')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "del col, df, stats, label, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7caf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings distribution\n",
    "ratings_distribution = df_train['rating'].value_counts(normalize=True).reset_index()\n",
    "ratings_distribution.columns = ['rating', 'percentage']\n",
    "\n",
    "# plot bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(ratings_distribution['rating'], ratings_distribution['percentage'], color='skyblue', edgecolor='black')\n",
    "\n",
    "# plot settings\n",
    "plt.title('Ratings Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Percentage of Ratings')\n",
    "plt.xticks(ratings_distribution['rating'], rotation=0)\n",
    "\n",
    "# add percentage to each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()\n",
    "del ratings_distribution, bars, bar, yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings distribution at the user or item level\n",
    "for col in ['user_id', 'item_id']:\n",
    "    df = (\n",
    "        df_train.groupby(by=[col, 'rating']).size()\n",
    "        .reset_index().rename(columns={0: 'size'})\n",
    "    )\n",
    "    df = (\n",
    "        df\n",
    "        .merge(\n",
    "            df.groupby(by=[col])['size'].sum()\n",
    "            .reset_index().rename(columns={'size': 't_size'})\n",
    "            , how='left', on=col\n",
    "            )\n",
    "        )\n",
    "    df['share'] = (df['size']/df['t_size']*100).round(1)\n",
    "    df = df.pivot(index=col, columns='rating', values='share').reset_index().fillna(0)\n",
    "\n",
    "    df['1v2'] = df[1] + df[2]\n",
    "    df['4v5'] = df[4] + df[5]\n",
    "\n",
    "    display(df.describe().round(1))\n",
    "del col, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()\n",
    "df['timestamp'] = pd.to_datetime(df_train['timestamp'], unit='s')\n",
    "df['year_week'] = df['timestamp'].dt.strftime('%Y-%U')\n",
    "\n",
    "for col in ['user_id', 'item_id']:\n",
    "    df_i = df.groupby(by=['year_week'])[col].nunique().reset_index()\n",
    "\n",
    "    # line plot to show active users per week\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_i['year_week'], df_i[col], marker='o', linestyle='-', color='b')\n",
    "    plt.title(f'Number of Active {col.split(sep=\"_\")[0].capitalize()}s per Week')\n",
    "    plt.xlabel('Year-Week')\n",
    "    plt.ylabel(f'Active {col.split(sep=\"_\")[0].capitalize()}s')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "del col, df_i, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9055a7",
   "metadata": {},
   "source": [
    "**Train/Test Split**\n",
    "\n",
    "- Identify share of items which are in the test set but not in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN/TEST SPLIT\n",
    "print(\n",
    "    \"Train set\\n\",\n",
    "    f'- num. items: {df_train[\"item_id\"].nunique()}\\n',\n",
    "    f'- pct. items: {round(df_train[\"item_id\"].nunique()/dfs[\"data\"][\"item_id\"].nunique()*100, 1)} %\\n'\n",
    "    )\n",
    "print(\n",
    "    \"Test set\\n\",\n",
    "    f'- num. items: {df_test[\"item_id\"].nunique()}\\n',\n",
    "    f'- pct. items: {round(df_test[\"item_id\"].nunique()/dfs[\"data\"][\"item_id\"].nunique()*100, 1)} %\\n'\n",
    "    )\n",
    "\n",
    "# items which are in test but not in train set\n",
    "new_items_t = set(df_test[\"item_id\"].unique()).difference(df_train[\"item_id\"].unique())\n",
    "print(\n",
    "    \"New Items\\n\",\n",
    "    f'- num. items: {len(new_items_t)}\\n',\n",
    "    f'- pct. items: {round(len(new_items_t)/dfs[\"data\"][\"item_id\"].nunique()*100, 1)}\\n',\n",
    "    \"\\n\", \"*\"*10, \"\\n\"\n",
    ")\n",
    "\n",
    "# TRAIN/VALIDATION SPLIT\n",
    "df_train, df_valid = leave_last_k(df=df_train, config=config['optimization'])\n",
    "\n",
    "print(\n",
    "    \"Train set\\n\",\n",
    "    f'- num. items: {df_train[\"item_id\"].nunique()}\\n',\n",
    "    f'- pct. items: {round(df_train[\"item_id\"].nunique()/dfs[\"data\"][\"item_id\"].nunique()*100, 1)} %\\n'\n",
    "    )\n",
    "print(\n",
    "    \"Validation set\\n\",\n",
    "    f'- num. items: {df_valid[\"item_id\"].nunique()}\\n',\n",
    "    f'- pct. items: {round(df_valid[\"item_id\"].nunique()/dfs[\"data\"][\"item_id\"].nunique()*100, 1)} %\\n'\n",
    "    )\n",
    "\n",
    "# items which are in validation but not in train set\n",
    "new_items_v = set(df_valid[\"item_id\"].unique()).difference(df_train[\"item_id\"].unique())\n",
    "print(\n",
    "    \"New Items\\n\",\n",
    "    f'- num. items: {len(new_items_v)}\\n',\n",
    "    f'- pct. items: {round(len(new_items_v)/dfs[\"data\"][\"item_id\"].nunique()*100, 1)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57af56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"data\"][dfs[\"data\"][\"item_id\"].isin(new_items_v)].groupby(by=[\"item_id\"]).size().describe()\n",
    "dfs[\"data\"][dfs[\"data\"][\"item_id\"].isin(new_items_t)].groupby(by=[\"item_id\"]).size().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2f411",
   "metadata": {},
   "source": [
    "**Negative Sampling**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
